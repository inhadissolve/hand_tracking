# import cv2
# import mediapipe as mp
# import numpy as np
# import tensorflow as tf
# import pandas as pd
# import os
# from sklearn.preprocessing import StandardScaler
#
# # âœ… í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
# model = tf.keras.models.load_model("sign_language_model.keras")  # ìµœì‹  Keras í˜•ì‹ ì‚¬ìš©
#
# # âœ… ì—¬ëŸ¬ ê°œì˜ ì œìŠ¤ì²˜ ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°
# gesture_labels = []
#
# # âœ… 'sign_data/' í´ë” ë‚´ì˜ ëª¨ë“  CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ìƒì„±
# data_folder = "sign_data"
# for file in os.listdir(data_folder):
#     if file.endswith("_data.csv"):  # ëª¨ë“  í•™ìŠµëœ CSV íŒŒì¼ ê²€ìƒ‰
#         df = pd.read_csv(os.path.join(data_folder, file))
#         unique_labels = df["Label"].unique()
#         gesture_labels.extend(unique_labels)
#
# # âœ… ì¤‘ë³µ ì œê±° í›„ ì •ë ¬ (ã„±~ã… ì „ì²´ í¬í•¨í•˜ë„ë¡ ì •ë¦¬)
# gesture_labels = sorted(list(set(gesture_labels)))
# print(f"âœ… ë¶ˆëŸ¬ì˜¨ ì œìŠ¤ì²˜ ë¼ë²¨: {gesture_labels}")
#
# # âœ… MediaPipe ì† ëœë“œë§ˆí¬ ì´ˆê¸°í™”
# mp_hands = mp.solutions.hands
# mp_drawing = mp.solutions.drawing_utils
#
# # âœ… ì›¹ìº  ì—´ê¸°
# cap = cv2.VideoCapture(0)
#
# # âœ… StandardScaler ë¡œë“œ (í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ì •ê·œí™” ë°©ì‹ ì‚¬ìš©)
# scaler = StandardScaler()
#
# # âœ… Temperature Scaling ê°’ (í™•ë¥ ì„ ì¡°ì •í•˜ê¸° ìœ„í•¨)
# temperature = 2.5  # í´ìˆ˜ë¡ ì‹ ë¢°ë„ ì¡°ì •ì´ ê°•í•˜ê²Œ ì ìš©ë¨
#
# # âœ… MediaPipe Hands ì‹¤í–‰
# with mp_hands.Hands(
#         max_num_hands=1,
#         min_detection_confidence=0.6,
#         min_tracking_confidence=0.6) as hands:
#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret:
#             break
#
#         # âœ… BGR â†’ RGB ë³€í™˜
#         frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
#         results = hands.process(frame_rgb)
#
#         if results.multi_hand_landmarks:
#             for hand_landmarks in results.multi_hand_landmarks:
#                 # âœ… ì† ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
#                 mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
#
#                 # âœ… ëœë“œë§ˆí¬ ì¢Œí‘œ ìˆ˜ì§‘ (ìƒëŒ€ ì¢Œí‘œ ë³€í™˜)
#                 hand_data = []
#                 for landmark in hand_landmarks.landmark:
#                     hand_data.append(landmark.x - hand_landmarks.landmark[0].x)  # ìƒëŒ€ ì¢Œí‘œ
#                     hand_data.append(landmark.y - hand_landmarks.landmark[0].y)
#                     hand_data.append(landmark.z)
#
#                 # âœ… ë°ì´í„° ì •ê·œí™” (StandardScaler ì‚¬ìš©)
#                 hand_data = np.array(hand_data).reshape(1, -1)  # (1, 63)
#                 hand_data = scaler.fit_transform(hand_data)  # í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì •ê·œí™”
#
#                 # âœ… ëœë¤ ë…¸ì´ì¦ˆ ì¶”ê°€ (ê³¼ì í•© ë°©ì§€)
#                 hand_data += np.random.normal(0, 0.01, hand_data.shape)
#
#                 # âœ… ëª¨ë¸ ì˜ˆì¸¡
#                 predictions = model.predict(hand_data)
#
#                 # âœ… Temperature Scaling ì ìš© (í™•ë¥  ì¡°ì •)
#                 scaled_predictions = np.exp(predictions / temperature) / np.sum(np.exp(predictions / temperature))
#
#                 # âœ… ì˜ˆì¸¡ í™•ë¥  ì •ë ¬
#                 sorted_indices = np.argsort(-scaled_predictions)[0]  # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
#                 max_index = sorted_indices[0]  # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤
#                 second_best_index = sorted_indices[1] if len(sorted_indices) > 1 else None  # ë‘ ë²ˆì§¸ í™•ë¥ 
#
#                 confidence = scaled_predictions[0, max_index] * 100  # ê°€ì¥ ë†’ì€ í™•ë¥  (0~100%)
#                 second_confidence = scaled_predictions[0, second_best_index] * 100 if second_best_index is not None else 0
#
#                 # âœ… íŠ¹ì • í™•ë¥  ì´í•˜ë¼ë©´ 'Unknown' ì²˜ë¦¬
#                 if confidence < 85 or (second_best_index is not None and confidence - second_confidence < 10):
#                     predicted_label = "Unknown"
#                     predicted_label_korean = "ì•Œ ìˆ˜ ì—†ìŒ"  # í•œê¸€ ë¼ë²¨ (ì½˜ì†” ì¶œë ¥ìš©)
#                 else:
#                     predicted_label = gesture_labels[max_index]
#                     predicted_label_korean = predicted_label  # í•œê¸€ ë¼ë²¨
#
#                 # âœ… ì½˜ì†”ì— í•œê¸€ë¡œ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
#                 print(f"ğŸ” ì˜ˆì¸¡ ê²°ê³¼: {predicted_label_korean}, ì‹ ë¢°ë„: {confidence:.2f}%")
#
#                 # âœ… ì›¹ìº  í™”ë©´ì—ì„œëŠ” ì˜ì–´ë¡œ í‘œì‹œ (í•œê¸€ì€ ê¹¨ì§)
#                 cv2.putText(frame, f"Predicted: {predicted_label}", (10, 50),
#                             cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
#
#                 # âœ… í™•ë¥  ê°’ë„ í‘œì‹œ
#                 cv2.putText(frame, f"Confidence: {confidence:.2f}%", (10, 80),
#                             cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
#
#         # âœ… í™”ë©´ ì¶œë ¥
#         cv2.imshow('Sign Language Recognition', frame)
#
#         # âœ… ESC í‚¤ë¡œ ì¢…ë£Œ
#         if cv2.waitKey(5) & 0xFF == 27:  # ESC í‚¤
#             break
#
# cap.release()
# cv2.destroyAllWindows()

import tensorflow as tf
import numpy as np
import pandas as pd

# 1. ëª¨ë¸ ë¡œë“œ
model = tf.keras.models.load_model("gesture_model.h5")  # í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ

# 2. ëª¨ë¸ êµ¬ì¡° í™•ì¸
print("### ëª¨ë¸ êµ¬ì¡° ###")
model.summary()  # ëª¨ë¸ì˜ ë ˆì´ì–´, íŒŒë¼ë¯¸í„° ìˆ˜, ì¶œë ¥ í˜•íƒœ ë“±ì„ í™•ì¸

# 3. ëª¨ë¸ì˜ í•™ìŠµëœ ê°€ì¤‘ì¹˜ í™•ì¸
print("\n### ëª¨ë¸ì˜ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ###")
weights = model.get_weights()
for i, weight in enumerate(weights):
    print(f"Layer {i} Weights shape: {weight.shape}")

# 4. ì¶œë ¥ ë ˆì´ì–´ í™œì„±í™” í•¨ìˆ˜ í™•ì¸
print("\n### ì¶œë ¥ ë ˆì´ì–´ í™œì„±í™” í•¨ìˆ˜ ###")
output_layer = model.layers[-1]
print(f"Output layer activation function: {output_layer.activation}")

# 5. í•™ìŠµ ë°ì´í„°ì˜ ë¼ë²¨ í™•ì¸
print("\n### í•™ìŠµ ë°ì´í„° ë¼ë²¨ í™•ì¸ ###")
df = pd.read_csv('sign_data/gesture_data.csv')  # í•™ìŠµì— ì‚¬ìš©ëœ ë°ì´í„°ì…‹ ê²½ë¡œ
print(f"Unique Labels: {df['Label'].unique()}")  # ë¼ë²¨ ëª©ë¡ í™•ì¸

# 6. í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
# ì˜ˆì‹œ ëœë¤ ë°ì´í„° (ì† ëœë“œë§ˆí¬ ì¢Œí‘œ í˜•íƒœë¡œ ê°€ì •)
test_data = np.random.rand(1, 63)  # 63ê°œ ëœë“œë§ˆí¬ ì¢Œí‘œë¡œ êµ¬ì„±ëœ ì…ë ¥ ë°ì´í„°
test_data = (test_data - 0.5) / 0.5  # ì •ê·œí™”

# ì˜ˆì¸¡ ìˆ˜í–‰
predictions = model.predict(test_data)

# ì˜ˆì¸¡ëœ ë¼ë²¨ê³¼ ê·¸ì— ëŒ€í•œ í™•ë¥  ì¶œë ¥
predicted_label = np.argmax(predictions, axis=1)  # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤
confidence = np.max(predictions) * 100  # ì˜ˆì¸¡ í™•ë¥ 

print(f"\n### ì˜ˆì¸¡ ê²°ê³¼ ###")
print(f"Predicted label: {predicted_label}")
print(f"Confidence: {confidence:.2f}%")

