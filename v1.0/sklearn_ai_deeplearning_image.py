# import tensorflow as tf
# import pandas as pd
# import numpy as np
# from sklearn.model_selection import train_test_split
#
# # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# df = pd.read_csv("sign_data/ã„±_data.csv")
#
# # ë°ì´í„° ê°œìˆ˜ í™•ì¸
# print(f"ğŸ“Š ë°ì´í„°ì…‹ í¬ê¸°: {df.shape}")
#
# # ì…ë ¥ ë°ì´í„° (ëœë“œë§ˆí¬ ì¢Œí‘œ)
# X = df.iloc[:, :-2].values  # ë§ˆì§€ë§‰ ë‘ ê°œ ì—´(Image, Label) ì œì™¸
# X = (X - 0.5) / 0.5  # ë°ì´í„° ì •ê·œí™” (-1 ~ 1 ë²”ìœ„)
#
# # ì¶œë ¥ ë°ì´í„° (ë¼ë²¨ì„ ì›-í•« ì¸ì½”ë”©)
# y = pd.get_dummies(df["Label"]).values  # ì›-í•« ì¸ì½”ë”©
#
# # ìƒ˜í”Œ ê°œìˆ˜ í™•ì¸ í›„ ë¶„í•  ë°©ì‹ ì¡°ì •
# num_samples = X.shape[0]
#
# if num_samples > 1:
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# else:
#     X_train, X_test, y_train, y_test = X, X, y, y
#     print("âš ï¸ ìƒ˜í”Œì´ 1ê°œë¿ì´ë¯€ë¡œ train_test_splitì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì „ì²´ ë°ì´í„°ë¥¼ í›ˆë ¨ì— ì‚¬ìš©í•©ë‹ˆë‹¤.")
#
# # âœ… Softmax or Sigmoid ìë™ ì„ íƒ
# if y.shape[1] > 1:
#     activation_function = 'softmax'
#     loss_function = 'categorical_crossentropy'
# else:
#     activation_function = 'sigmoid'
#     loss_function = 'binary_crossentropy'
#
# # MLP ëª¨ë¸ ì •ì˜
# model = tf.keras.Sequential([
#     tf.keras.layers.Dense(128, activation='relu', input_shape=(X.shape[1],)),
#     tf.keras.layers.Dropout(0.3),
#     tf.keras.layers.Dense(64, activation='relu'),
#     tf.keras.layers.Dropout(0.3),
#     tf.keras.layers.Dense(y.shape[1], activation=activation_function)  # softmax ë˜ëŠ” sigmoid ìë™ ì ìš©
# ])
#
# # ëª¨ë¸ ì»´íŒŒì¼
# model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])
#
# # ëª¨ë¸ í•™ìŠµ
# model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))
#
# # âœ… ìµœì‹  Keras ì €ì¥ ë°©ì‹ ì‚¬ìš©
# model.save("sign_language_model.keras")  # .h5 â†’ .keras ë³€ê²½
# print("âœ… ì† ëœë“œë§ˆí¬ ê¸°ë°˜ AI ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ë° ì €ì¥ë¨!")

import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ì˜ˆì‹œ ë°ì´í„° (ì† ëœë“œë§ˆí¬ ì¢Œí‘œì™€ ë¼ë²¨)
X = np.random.rand(100, 63)  # ëœë¤ ë°ì´í„° (100ê°œì˜ ìƒ˜í”Œ, ê° ìƒ˜í”Œì€ 63ê°œì˜ ëœë“œë§ˆí¬ ì¢Œí‘œ)
y = np.random.randint(0, 4, 100)  # 4ê°œì˜ í´ë˜ìŠ¤(ì˜ˆ: thumbs_down, victory, thumbs_up, pointing_up)

# ë°ì´í„° ì •ê·œí™”
scaler = StandardScaler()
X = scaler.fit_transform(X)

# í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ëª¨ë¸ ì •ì˜
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X.shape[1],)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(4, activation='softmax')  # 4ê°œì˜ í´ë˜ìŠ¤(thumbs_down, victory, thumbs_up, pointing_up)
])

# ëª¨ë¸ ì»´íŒŒì¼
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# ëª¨ë¸ í•™ìŠµ
model.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test))

# ëª¨ë¸ ì €ì¥
model.save("gesture_model.h5")  # ëª¨ë¸ì„ 'gesture_model.h5'ë¡œ ì €ì¥
print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ë° ì €ì¥ë¨!")
